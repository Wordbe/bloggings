# Spark 6 - Spark SQL and DataSet



데이터세트 구조를 고수준 API 로 사용하기 위해 스파크가 메모리를 관리하는 방법, 비용 등을 알아보자.



## 자바와 스칼라를 위한 단일 API

## DateSet 을 위한 Scala case class, Java bean

## DataSet, DataFrame 을 위한 메모리 관리

- Spark 2.x 부터 2세대 텅스텐 엔진 도입
  - 전체 단계 코드 생성, 벡터화된 컬럼 기반 메모리 레이이웃 가짐
  - 단일 명령, 다중 데이터(SIMD) 접근 방식의 최신 CPU, 캐시 아키텍처를 활용해서 빠른 병렬 데이터 접근을 지원
- 데이터 집합 인코더
  - 오프 힙 메모리의 데이터를 스파크 내부 텅스텐 포맷에서 JVM 자바 오브젝트로 변환한다.
  - DataSet 객체를 직렬화, 역직렬화한다. `Encoder[T]` 는 스파크 내부 텅스텐 형식에서 `DataSet[T]` 로 변환딘다.
- 스파크 내부 형식
  - 스파크는 JVM 기반 객체 생성 대신, 오프 힙 자바 메모리를 할당하여 데이터를 레이아웃하고 인코더를 사용하여 데이터를 메모리 내 표현에서 JVM 객체로 변환한다
- 직렬화, 역직렬화
  - 분산 컴퓨팅에서 클러스터 내 노드들 사이에 데이터가 네트워크를 통해 자주 이동.
  - 직렬화, 역직렬화 : 송신자가 이진형식으로 인코딩(직렬화), 수신자가 데이터형식으로 디코딩(역직렬화)

## DataSet 사용 비용

대규모 데이터 세트에서는 직렬화/역직렬화로 비용이 발생할 수 있음.

- 비용 절감 전략

  - 쿼리에서 DSL 표현을 사용하고, 람다를 과도하게 사용하는 것을 지양

    ```scala
    personDS
    	.filter(year($"birthDate") > earliestYear)
    	.filter($"salary" > 80000)
    	// .filter(x => x.lastName.startsWith("J")) 람다를 중간에 사용하면 텅스텐으로 역직렬화, 직렬화 필요
    	.filter($"lastName".startWith("J"))
    	.count()
    ```

    